{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "from cmcrameri import cm\n",
    "from pymannkendall import original_test\n",
    "\n",
    "\n",
    "folder_ts = r'Data\\Datasets\\amz\\ts'\n",
    "folder_metric = r'Data\\Datasets\\amz\\amp'\n",
    "datasets = ['cru', 'gpcc', 'chirps','imerg', 'terra', 'era_land', 'jra55','merra2']\n",
    "datasets_names = ['CRU', 'GPCC', 'CHIRPS','IMERG-V6', 'TerraClimate', 'ERA5-Land', 'JRA55','MERRA2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def mannkendall_trend(arr):\n",
    "    if not np.isnan(arr).any():\n",
    "        result = original_test(arr)\n",
    "        return result.p, result.slope, result.intercept\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "def ds_kendall(data, dim, var='pr'):\n",
    "    results =  xr.apply_ufunc(mannkendall_trend, data,\n",
    "                             input_core_dims=[[dim]],\n",
    "                             output_core_dims=[[], [],[]],\n",
    "                             vectorize=True,\n",
    "                             dask='parallelized')\n",
    "    \n",
    "    \n",
    "    # Extract the p-values and Sen's slopes from the results\n",
    "    p_values = results[0]\n",
    "    slopes = results[1]\n",
    "    intercepts = results[2]\n",
    "    \n",
    "    # Create a new xarray dataset to store the results\n",
    "    results_dataset = xr.Dataset({'p_values': p_values[var], 'slopes': slopes[var], 'intercepts': intercepts[var]})\n",
    "    return results_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ts clim trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    #read file of dataset in folder_clean\n",
    "    file_path = glob(os.path.join(folder_ts, dataset + '.nc'))\n",
    "    ds = xr.open_dataset(file_path[0])\n",
    "    maxx = ds.groupby('time.year').max('time')\n",
    "    minn = ds.groupby('time.year').min('time')\n",
    "    ds_ts = ( maxx - minn).pr.rename('amp').to_dataset()\n",
    "    ds_ts['max'] = maxx.pr\n",
    "    ds_ts['min'] = minn.pr\n",
    "    ds_clim = ds_ts.mean('year')\n",
    "    ds_trend =  ds_kendall(ds_ts, 'year', var='amp')\n",
    "    #save\n",
    "    ds_ts.to_netcdf(os.path.join(folder_metric, dataset + '.nc'))\n",
    "    ds_clim.to_netcdf(os.path.join(folder_metric,'clim', dataset + '.nc'))\n",
    "    ds_trend.to_netcdf(os.path.join(folder_metric,'trend', dataset + '.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = gpd.read_file(r'Data\\Evaluation\\stations_amz_ANA.geojson')\n",
    "df_stat= pd.read_pickle(r'Data\\Evaluation\\amz_01_20_20bet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df_stat.groupby(['Code', df_stat.Date.dt.year])['Total'].max().reset_index()\n",
    "df_ts.rename(columns={'Total':'max'}, inplace=True)\n",
    "df_ts['min'] = df_stat.groupby(['Code', df_stat.Date.dt.year])['Total'].min().reset_index()['Total']\n",
    "df_ts['amp'] = df_ts['max'] - df_ts['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clim = df_ts.groupby('Code')[['amp', 'min', 'max']].mean().reset_index()\n",
    "stations = stations.merge(df_clim, on='Code')\n",
    "for code in df_ts.Code.unique():\n",
    "    test = original_test(df_ts[df_ts.Code == code]['amp'])\n",
    "    stations.loc[stations.Code == code, 'p'+ '_' + 'amp'] = test.p\n",
    "    stations.loc[stations.Code == code, 'slope'+ '_' + 'amp'] = test.slope\n",
    "    stations.loc[stations.Code == code, 'intercept'+ '_' + 'amp'] = test.intercept\n",
    "\n",
    "#save stations as stations map\n",
    "stations.to_file(os.path.join(folder_metric, 'stations.geojson'), driver='GeoJSON')\n",
    "df_ts.to_csv(os.path.join(folder_metric, 'stations_ts.csv'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
