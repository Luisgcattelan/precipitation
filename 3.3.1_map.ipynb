{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from pymannkendall import original_test\n",
    "shp_pan = gpd.read_file(r'Data\\shapefiles\\panamz.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ts = r'Data\\Datasets\\amz\\ts'\n",
    "folder_metric = r'Data\\Datasets\\amz\\map'\n",
    "datasets = ['cru', 'gpcc', 'chirps','imerg', 'terra', 'era_land', 'jra55','merra2']\n",
    "datasets_names = ['CRU', 'GPCC', 'CHIRPS','IMERG-V6', 'TerraClimate', 'ERA5-Land', 'JRA55','MERRA2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def mannkendall_trend(arr):\n",
    "    if not np.isnan(arr).any():\n",
    "        result = original_test(arr)\n",
    "        return result.p, result.slope, result.intercept\n",
    "    else:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "def ds_kendall(data, dim):\n",
    "    results =  xr.apply_ufunc(mannkendall_trend, data,\n",
    "                             input_core_dims=[[dim]],\n",
    "                             output_core_dims=[[], [],[]],\n",
    "                             vectorize=True,\n",
    "                             dask='parallelized')\n",
    "    \n",
    "    \n",
    "    # Extract the p-values and Sen's slopes from the results\n",
    "    p_values = results[0]\n",
    "    slopes = results[1]\n",
    "    intercepts = results[2]\n",
    "    \n",
    "    # Create a new xarray dataset to store the results\n",
    "    results_dataset = xr.Dataset({'p_values': p_values.pr, 'slopes': slopes.pr, 'intercepts': intercepts.pr})\n",
    "    return results_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ts clim trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    #read file of dataset in folder_clean\n",
    "    file_path = glob(os.path.join(folder_ts, dataset + '.nc'))\n",
    "    ds = xr.open_dataset(file_path[0])\n",
    "    ds_ts = ds.groupby('time.year').mean('time')\n",
    "    #pr times 12\n",
    "    ds_ts['pr'] = ds_ts['pr'] * 12\n",
    "    ds_clim = ds_ts.mean('year')\n",
    "    ds_trend =  ds_kendall(ds_ts, 'year')\n",
    "    #save\n",
    "    ds_ts.to_netcdf(os.path.join(folder_metric, dataset + '.nc'))\n",
    "    ds_clim.to_netcdf(os.path.join(folder_metric,'clim', dataset + '.nc'))\n",
    "    ds_trend.to_netcdf(os.path.join(folder_metric,'trend', dataset + '.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisg\\AppData\\Local\\Temp\\ipykernel_20548\\2175440526.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ts = df_stat.groupby(['Code',df_stat.Date.dt.year]).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "stations = gpd.read_file(r'Data\\Evaluation\\stations_amz_ANA.geojson')\n",
    "df_stat= pd.read_pickle(r'Data\\Evaluation\\amz_01_20_20bet.pkl')\n",
    "df_ts = df_stat.groupby(['Code',df_stat.Date.dt.year]).sum().reset_index()\n",
    "df_clim = df_ts.groupby('Code').mean().reset_index()\n",
    "stations = stations.merge(df_clim, on='Code')\n",
    "for code in df_ts.Code.unique():\n",
    "    test = original_test(df_ts[df_ts.Code == code]['Total'])\n",
    "    stations.loc[stations.Code == code, 'p'+ '_' + 'anual'] = test.p\n",
    "    stations.loc[stations.Code == code, 'slope'+ '_' + 'anual'] = test.slope\n",
    "    stations.loc[stations.Code == code, 'intercept'+ '_' + 'anual'] = test.intercept\n",
    "\n",
    "#save stations as stations map\n",
    "stations.to_file(os.path.join(folder_metric, 'stations.geojson'), driver='GeoJSON')\n",
    "df_ts.to_csv(os.path.join(folder_metric, 'stations_ts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "terra = xr.open_dataset(r'Data\\Datasets\\amz\\map\\clim\\terra.nc')\n",
    "folder_metric = r'Data\\Datasets\\amz\\map\\clim'\n",
    "folder_metric_int = r'Data\\Datasets\\amz\\map\\clim\\int'\n",
    "datasets = ['cru', 'gpcc', 'chirps','imerg', 'terra', 'era_land', 'jra55','merra2']\n",
    "datasets_names = ['CRU', 'GPCC', 'CHIRPS','IMERG-V6', 'TerraClimate', 'ERA5-Land', 'JRA55','MERRA2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate all datasets to terra grid and unite in a single dataset\n",
    "list_ds = []\n",
    "for i,dataset in enumerate(datasets):\n",
    "    ds = xr.open_dataset(os.path.join(folder_metric, dataset + '.nc'))\n",
    "    ds_int = ds.interp_like(terra, method='nearest')\n",
    "    ds_int = ds_int[['pr']]\n",
    "    ds_int.to_netcdf(os.path.join(folder_metric_int, dataset + '.nc'))\n",
    "    ds_int['dataset'] = datasets_names[i]\n",
    "    list_ds.append(ds_int)\n",
    "ds_all = xr.concat(list_ds, dim='dataset')\n",
    "ds_all.to_netcdf(os.path.join(folder_metric_int, 'all.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_extras = ['cpc', 'cmap','cmorph', 'gpcp', 'persiann', 'ccs', 'cdr', 'mswep',\n",
    "                    'mswep_nogauge', 'gldas','worldclim', 'era', 'ncep1', 'ncep2']\n",
    "\n",
    "datasets_names_extras = ['CPC', 'CMAP','CMORPH', 'GPCP v3.2', 'PERSIANN', 'PERSIANN-CCS', 'PERSIANN-CDR', 'MSWEP v2.8',\n",
    "                    'MSWEP_nogauge v2.8', 'GLDAS v2.1','WorldClim', 'ERA5', 'NCEP R1', 'NCEP R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_extras = ['ccs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccs\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets_extras:\n",
    "    #read file of dataset in folder_clean\n",
    "    file_path = glob(os.path.join(folder_ts, dataset + '.nc'))\n",
    "    ds = xr.open_dataset(file_path[0])\n",
    "    ds_ts = ds.groupby('time.year').mean('time')\n",
    "    #pr times 12\n",
    "    ds_ts['pr'] = ds_ts['pr'] * 12\n",
    "    ds_clim = ds_ts.mean('year')\n",
    "    ds_trend =  ds_kendall(ds_ts, 'year')\n",
    "    #save\n",
    "    ds_ts.to_netcdf(os.path.join(folder_metric, dataset + '.nc'))\n",
    "    ds_clim.to_netcdf(os.path.join(folder_metric,'clim', dataset + '.nc'))\n",
    "    ds_trend.to_netcdf(os.path.join(folder_metric,'trend', dataset + '.nc'))\n",
    "    print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
